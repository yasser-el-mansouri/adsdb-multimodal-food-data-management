"""
Exploitation Zone - Task 2 - Multi modal search

This module shows an example of multi modal search in the Exploitation Zone.
It does separate text and image searches that return both text and image results.
"""

import io
import os
from typing import Any, Dict, Iterable, List, Optional

import chromadb
import numpy as np
from chromadb import PersistentClient
from chromadb.utils.embedding_functions import OpenCLIPEmbeddingFunction
from PIL import Image

# Import shared utilities
from app.utils.shared import Logger, PipelineConfig, S3Client, error_handler, utc_timestamp




class ExploitationMultiModalSearcher:
    """Processor for multi modal search"""

    def __init__(self, config: PipelineConfig):
        """Initialize the processor."""
        self.config = config
        self.logger = Logger("task_2_multi_modal_search", config.get("monitoring.log_level", "INFO"))
        self.s3_client = S3Client(config)

        # Configuration
        self.src_bucket = config.get("storage.buckets.trusted_zone")
        self.src_prefix = config.get("storage.prefixes.trusted_images")

        # ChromaDB configuration
        chromadb_config = config.get("chromadb_multimodal", {})
        self.persist_dir = chromadb_config.get(
            "persist_dir", "app/zones/exploitation_zone/chroma_exploitation"
        )

        chromadb_config_multi = config.get("chromadb_multimodal", {})
        self.collection_name_multi = chromadb_config_multi.get("collection_name", "exploitation_multimodal")
        self.embedding_model_multi = chromadb_config_multi.get("embedding_model", "OpenCLIP")
        self.metadata_multi = chromadb_config_multi.get("metadata", {})

        # Initialize ChromaDB client and embedding function
        self.chroma_client = PersistentClient(path=self.persist_dir)
        self.ef_multimodal = OpenCLIPEmbeddingFunction()

        # Initialize ChromaDB collection
        multi_collection_kwargs = {"name": self.collection_name_multi, "embedding_function": self.ef_multimodal}

        # Only add metadata if it's not empty
        if self.metadata_multi:
            multi_collection_kwargs["metadata"] = self.metadata_multi

        self.multi_col = self.chroma_client.get_or_create_collection(**multi_collection_kwargs)

        self.logger.info(f"ChromaDB directory: {self.persist_dir}")

    def summarize(self, label, arr):
        if not arr:
            print(f"No {label} results found.")
            return None, None
        return min(arr), max(arr)
    
    # --- Print multi-modal search summary ---
    def print_summary(self, res: Dict[str, Any]) -> str:
        metas = res["metadatas"][0]
        dists = res["distances"][0]

        image_dists = [d for m, d in zip(metas, dists) if m.get("type") == "image"]
        text_dists  = [d for m, d in zip(metas, dists) if m.get("type") == "text"]

        closest_img, farthest_img = self.summarize("image", image_dists)
        closest_txt, farthest_txt = self.summarize("text", text_dists)

        # --- Print the summary neatly ---
        def safe_fmt(x):
            return f"{x:.3f}" if x is not None else "N/A"
        res = (
            f"Closest image match has distance  {safe_fmt(closest_img)}\n"
            f"Farthest image match has distance {safe_fmt(farthest_img)}\n"
            f"Closest recipe match has distance {safe_fmt(closest_txt)}\n"
            f"Farthest recipe match has distance {safe_fmt(farthest_txt)}"
        )
        return res

    def text_search(self) -> str:
        all_data = self.multi_col.get(limit=10000)
        metas = all_data["metadatas"]

        image_count = sum(1 for m in metas if m.get("type") == "image")
        text_count  = sum(1 for m in metas if m.get("type") == "text")

        print(f"Total items: {len(metas)} | Images: {image_count} | Texts: {text_count}")

        query = "fettuccine alfredo pasta dish with creamy sauce"

        res = self.multi_col.query(
            query_texts=[query],
            n_results=85,
            include=["metadatas", "documents", "distances"]
        )

        res_string = self.print_summary(res)

        self.logger.info(f"Text search completed. result:\n {res_string}")
        
        return res_string

    def image_search(self) -> str:
        all_data = self.multi_col.get(limit=10000)
        metas = all_data["metadatas"]

        image_count = sum(1 for m in metas if m.get("type") == "image")
        text_count  = sum(1 for m in metas if m.get("type") == "text")

        print(f"Total items: {len(metas)} | Images: {image_count} | Texts: {text_count}")

        query = np.array(Image.open("calico-beans.jpg").convert("RGB"))

        res = self.multi_col.query(
            query_images=[query],
            n_results=85,    # top-k results
            include=["documents", "metadatas", "distances"]
        )
        res_string = self.print_summary(res)

        self.logger.info(f"Image search completed. result:\n {res_string}")

        return res_string



def main():
    """Main entry point for exploitation images processing."""
    config = PipelineConfig()
    searcher = ExploitationMultiModalSearcher(config)

    try:
        text_result = searcher.text_search()
        print("✅ Text search completed successfully")
        print(f"📊 Results: {text_result}")
        image_result = searcher.image_search()
        print("✅ Image search completed successfully")
        print(f"📊 Results: {image_result}")
    except Exception as e:
        print(f"❌ Multi modal search failed: {e}")
        raise


if __name__ == "__main__":
    main()