{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8d08d1e",
   "metadata": {},
   "source": [
    "# Trusted Zone â€” Images Processing\n",
    "\n",
    "This notebook handles the **image processing** step for the Trusted Zone of our data pipeline.  \n",
    "Its primary goal is to:\n",
    "\n",
    "1. **Extract recipe IDs** from image filenames in the Formatted Zone\n",
    "2. **Identify which recipes have images** and build a mapping\n",
    "3. **Copy filtered images** to the Trusted Zone (only images with valid recipes)\n",
    "4. **Generate a recipe IDs file** for the documents processing step\n",
    "\n",
    "This notebook works in conjunction with `documents.ipynb` to ensure data integrity in the Trusted Zone.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b2344e",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3422ede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, re\n",
    "from pathlib import PurePosixPath\n",
    "from datetime import datetime, timezone\n",
    "from typing import Dict, List, Set, Iterable\n",
    "\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# S3 / MinIO Configuration\n",
    "MINIO_USER     = os.getenv(\"MINIO_USER\")\n",
    "MINIO_PASSWORD = os.getenv(\"MINIO_PASSWORD\")\n",
    "MINIO_ENDPOINT = os.getenv(\"MINIO_ENDPOINT\")\n",
    "\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=MINIO_USER,\n",
    "    aws_secret_access_key=MINIO_PASSWORD,\n",
    "    region_name=\"us-east-1\"\n",
    ")\n",
    "s3 = session.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    config=Config(signature_version=\"s3v4\", s3={\"addressing_style\": \"path\"})\n",
    ")\n",
    "\n",
    "# Paths and Buckets\n",
    "FORM_BUCKET         = \"formatted-zone\"\n",
    "FORM_IMAGES_PREFIX  = \"images\"\n",
    "\n",
    "TRUST_BUCKET        = \"trusted-zone\"\n",
    "TRUST_IMAGES_PREFIX = \"images\"\n",
    "TRUST_REPORT_PREFIX = \"reports\"\n",
    "\n",
    "# Output file for documents processing\n",
    "RECIPE_IDS_FILE = \"recipe_ids_with_images.json\"\n",
    "\n",
    "# Behavior flags\n",
    "DRY_RUN   = False\n",
    "OVERWRITE = True\n",
    "\n",
    "def utc_ts():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H-%M-%SZ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7cae1e",
   "metadata": {},
   "source": [
    "## 2. S3 Helper Functions\n",
    "\n",
    "These utility functions provide a clean interface for S3 operations, handling common patterns like listing objects, checking existence, and copying files between buckets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92e69fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_list_keys(bucket: str, prefix: str) -> Iterable[str]:\n",
    "    \"\"\"List all object keys in a bucket with the given prefix.\"\"\"\n",
    "    paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix):\n",
    "        for obj in page.get(\"Contents\", []) or []:\n",
    "            key = obj[\"Key\"]\n",
    "            if not key.endswith(\"/\"):\n",
    "                yield key\n",
    "\n",
    "def s3_head(bucket: str, key: str):\n",
    "    \"\"\"Get object metadata, return None if not found.\"\"\"\n",
    "    try:\n",
    "        return s3.head_object(Bucket=bucket, Key=key)\n",
    "    except ClientError as e:\n",
    "        if e.response.get(\"Error\", {}).get(\"Code\") in (\"404\", \"NoSuchKey\", \"NotFound\"):\n",
    "            return None\n",
    "        raise\n",
    "\n",
    "def s3_copy_object(src_bucket: str, src_key: str, dst_bucket: str, dst_key: str, overwrite: bool = True):\n",
    "    \"\"\"Copy an object between buckets with optional overwrite control.\"\"\"\n",
    "    if not overwrite and s3_head(dst_bucket, dst_key) is not None:\n",
    "        return \"skip-exists\"\n",
    "    return s3.copy_object(\n",
    "        Bucket=dst_bucket,\n",
    "        Key=dst_key,\n",
    "        CopySource={\"Bucket\": src_bucket, \"Key\": src_key},\n",
    "        MetadataDirective=\"COPY\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6326c57",
   "metadata": {},
   "source": [
    "## 3. Extract Recipe IDs from Image Filenames\n",
    "\n",
    "Each image stored in the Formatted Zone follows a structured naming convention that encodes metadata, including the recipe identifier.  \n",
    "The general pattern is:\n",
    "\n",
    "**fileType$dataSource$ingestionTimestamp$hash__recipeId_positionOnImagesUrlArrayFromLayer2.extension**\n",
    "\n",
    "From these filenames, we extract the `recipeId` using a regular expression.  \n",
    "This allows us to associate every image with its corresponding recipe entry, even when multiple images exist for the same recipe.  \n",
    "The result of this step is two structures:\n",
    "\n",
    "- `img_ids`: a set of **unique recipe IDs** that have at least one image.\n",
    "- `id_to_imgkeys`: a dictionary mapping each `recipeId` to **all its image keys** (to preserve one-to-many relationships).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1bdba8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting recipe IDs from image filenames...\n",
      "[INFO] scanned image keys: 11\n",
      "[INFO] unique recipeIds with images: 7\n",
      "[INFO] total image files matched to recipeIds: 11\n"
     ]
    }
   ],
   "source": [
    "# Regular expression to extract recipe ID from image filenames\n",
    "# Recognizes names like:\n",
    "#   images/type$src$ts$hash__000018c8a5_0.jpg\n",
    "#   images/type$src$ts$hash__abcd_ef-12_3.JPEG\n",
    "# ID part: letters, digits, underscore, dash\n",
    "ID_REGEX = re.compile(\n",
    "    r\"__([A-Za-z0-9_\\-]+)_(\\d+)\\.(?:jpe?g|png|webp|gif|bmp|tiff)$\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "def recipe_id_from_image_key(key: str) -> str | None:\n",
    "    \"\"\"Extract recipe ID from an image S3 key.\"\"\"\n",
    "    name = PurePosixPath(key).name\n",
    "    m = ID_REGEX.search(name)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "print(\"Extracting recipe IDs from image filenames...\")\n",
    "\n",
    "img_ids: Set[str] = set()                    # unique IDs (for filtering)\n",
    "id_to_imgkeys: Dict[str, List[str]] = {}     # ALL images per ID\n",
    "\n",
    "count_keys = 0\n",
    "for key in s3_list_keys(FORM_BUCKET, FORM_IMAGES_PREFIX + \"/\"):\n",
    "    count_keys += 1\n",
    "    rid = recipe_id_from_image_key(key)\n",
    "    if not rid:\n",
    "        continue\n",
    "    img_ids.add(rid)\n",
    "    id_to_imgkeys.setdefault(rid, []).append(key)\n",
    "\n",
    "# Make copies deterministic (optional)\n",
    "for rid in id_to_imgkeys:\n",
    "    id_to_imgkeys[rid].sort()\n",
    "\n",
    "total_images = sum(len(v) for v in id_to_imgkeys.values())\n",
    "print(f\"[INFO] scanned image keys: {count_keys}\")\n",
    "print(f\"[INFO] unique recipeIds with images: {len(img_ids)}\")\n",
    "print(f\"[INFO] total image files matched to recipeIds: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7256b8",
   "metadata": {},
   "source": [
    "## 4. Save Recipe IDs for Documents Processing\n",
    "\n",
    "We save the extracted recipe IDs to a JSON file that will be used by the `documents.ipynb` notebook to filter the recipe documents. This creates a clean separation between image and document processing while maintaining the necessary coupling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8dce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] saved recipe IDs to recipe_ids_with_images.json\n",
      "[INFO] 7 recipe IDs will be used for document filtering\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for documents processing\n",
    "recipe_ids_data = {\n",
    "    \"timestamp\": utc_ts(),\n",
    "    \"source\": f\"s3://{FORM_BUCKET}/{FORM_IMAGES_PREFIX}/\",\n",
    "    \"total_images_scanned\": count_keys,\n",
    "    \"unique_recipe_ids\": len(img_ids),\n",
    "    \"total_images_matched\": total_images,\n",
    "    \"recipe_ids_with_images\": sorted(list(img_ids)),\n",
    "    \"recipe_to_images\": {rid: keys for rid, keys in id_to_imgkeys.items()}\n",
    "}\n",
    "\n",
    "# Save to local file\n",
    "with open(RECIPE_IDS_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(recipe_ids_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"[OK] saved recipe IDs to {RECIPE_IDS_FILE}\")\n",
    "print(f\"[INFO] {len(img_ids)} recipe IDs will be used for document filtering\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48ffae",
   "metadata": {},
   "source": [
    "## 5. Copy Images to Trusted Zone\n",
    "\n",
    "Now we copy all the images that have valid recipe IDs from the **Formatted Zone** to the **Trusted Zone**.  \n",
    "We preserve the original filenames to maintain traceability and ensure that the image-to-recipe mapping remains intact.\n",
    "\n",
    "This step ensures that:\n",
    "- Only images with corresponding recipe entries are copied\n",
    "- All images for a recipe are preserved (multiple images per recipe)\n",
    "- Original filenames and metadata are maintained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f43e912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying images to Trusted Zone...\n",
      "[STATS] images copied=11 skipped=0\n"
     ]
    }
   ],
   "source": [
    "print(\"Copying images to Trusted Zone...\")\n",
    "\n",
    "copied = skipped = 0\n",
    "\n",
    "if DRY_RUN:\n",
    "    print(\"[DRY_RUN] Would copy the following images:\")\n",
    "    for rid, keys in id_to_imgkeys.items():\n",
    "        for src_key in keys:\n",
    "            dst_key = f\"{TRUST_IMAGES_PREFIX}/{PurePosixPath(src_key).name}\"\n",
    "            print(f\"  {src_key} -> {dst_key}\")\n",
    "    copied = total_images\n",
    "else:\n",
    "    # Copy all images for IDs that have valid recipes\n",
    "    for rid, keys in id_to_imgkeys.items():\n",
    "        # keys are full 'images/...' relative keys in formatted-zone\n",
    "        for src_key in keys:\n",
    "            dst_key = f\"{TRUST_IMAGES_PREFIX}/{PurePosixPath(src_key).name}\"\n",
    "            try:\n",
    "                result = s3_copy_object(FORM_BUCKET, src_key, TRUST_BUCKET, dst_key, overwrite=OVERWRITE)\n",
    "                if result == \"skip-exists\":\n",
    "                    print(f\"[SKIP] {dst_key} already exists\")\n",
    "                    skipped += 1\n",
    "                else:\n",
    "                    copied += 1\n",
    "            except ClientError as e:\n",
    "                print(f\"[WARN] copy failed {src_key} -> {dst_key}: {e}\")\n",
    "                skipped += 1\n",
    "\n",
    "print(f\"[STATS] images copied={copied} skipped={skipped}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec44ad",
   "metadata": {},
   "source": [
    "## 6. Generate Processing Report\n",
    "\n",
    "Finally, we generate a comprehensive report of the image processing step and save it to the Trusted Zone for audit and monitoring purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93805aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] wrote report -> s3://trusted-zone/reports/\n",
      "\n",
      "============================================================\n",
      "IMAGES PROCESSING COMPLETE\n",
      "============================================================\n",
      "Next step: Run documents.ipynb to filter recipe documents\n",
      "Recipe IDs file: recipe_ids_with_images.json\n"
     ]
    }
   ],
   "source": [
    "report = {\n",
    "    \"timestamp\": utc_ts(),\n",
    "    \"processing_step\": \"images\",\n",
    "    \"source_images_prefix\": f\"s3://{FORM_BUCKET}/{FORM_IMAGES_PREFIX}/\",\n",
    "    \"destination_images_prefix\": f\"s3://{TRUST_BUCKET}/{TRUST_IMAGES_PREFIX}/\",\n",
    "    \"total_images_scanned\": count_keys,\n",
    "    \"unique_recipe_ids_with_images\": len(img_ids),\n",
    "    \"total_images_matched\": total_images,\n",
    "    \"images_copied\": copied,\n",
    "    \"images_skipped\": skipped,\n",
    "    \"recipe_ids_file\": RECIPE_IDS_FILE,\n",
    "    \"dry_run\": DRY_RUN,\n",
    "    \"overwrite\": OVERWRITE\n",
    "}\n",
    "\n",
    "if not DRY_RUN:\n",
    "    s3.put_object(\n",
    "        Bucket=TRUST_BUCKET,\n",
    "        Key=f\"{TRUST_REPORT_PREFIX}/images_processing_{utc_ts()}.json\",\n",
    "        Body=json.dumps(report, ensure_ascii=False, indent=2).encode(\"utf-8\"),\n",
    "        ContentType=\"application/json\"\n",
    "    )\n",
    "    print(f\"[OK] wrote report -> s3://{TRUST_BUCKET}/{TRUST_REPORT_PREFIX}/\")\n",
    "else:\n",
    "    print(\"[DRY_RUN] report:\", json.dumps(report, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMAGES PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Next step: Run documents.ipynb to filter recipe documents\")\n",
    "print(f\"Recipe IDs file: {RECIPE_IDS_FILE}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
