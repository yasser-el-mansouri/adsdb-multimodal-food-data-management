{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d47de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import io\n",
    "import re\n",
    "import boto3\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import PurePosixPath\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "from PIL import Image\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SRC_BUCKET      = \"landing-zone\"\n",
    "SRC_PREFIX      = \"persistent_landing/images\"      \n",
    "DST_BUCKET      = \"formatted-zone\"\n",
    "DST_PREFIX      = \"images\"\n",
    "HF_DATASET      = os.getenv(\"HF_DATASET\")\n",
    "\n",
    "MINIO_USER=os.getenv(\"MINIO_USER\")\n",
    "MINIO_PASSWORD=os.getenv(\"MINIO_PASSWORD\")\n",
    "MINIO_ENDPOINT=os.getenv(\"MINIO_ENDPOINT\")\n",
    "\n",
    "TARGET_EXT      = \"jpg\" \n",
    "TARGET_PIL_FMT  = \"JPEG\"\n",
    "TARGET_CTYPE    = \"image/jpeg\"\n",
    "\n",
    "OVERWRITE = False\n",
    "\n",
    "JPEG_SAVE_KW = dict(\n",
    "    quality=90,\n",
    "    optimize=True,\n",
    "    progressive=True,\n",
    "    subsampling=\"4:2:0\",\n",
    ")\n",
    "\n",
    "session = boto3.session.Session(\n",
    "    aws_access_key_id=MINIO_USER,\n",
    "    aws_secret_access_key=MINIO_PASSWORD,\n",
    "    region_name=\"us-east-1\",\n",
    ")\n",
    "s3 = session.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    config=Config(signature_version=\"s3v4\", s3={\"addressing_style\": \"path\"}),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6165e3",
   "metadata": {},
   "source": [
    "This block loads environment variables and prepares MinIO access (via **boto3**) for an image formatting step. It defines source/destination buckets and prefixes, the dataset name, and target image settings: convert to **JPEG** (`.jpg`) with a fixed content type and PIL format.\n",
    "\n",
    "It also sets overwrite behavior and JPEG save options (quality, optimization, progressive, subsampling) to standardize output size and quality. Finally, it creates a boto3 session/client pointed at the MinIO endpoint using credentials from `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7b351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utc_ts() -> str:\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H-%M-%SZ\")\n",
    "\n",
    "\n",
    "def split_name(key: str):\n",
    "    name = PurePosixPath(key).name\n",
    "    base = PurePosixPath(name).stem\n",
    "    ext  = PurePosixPath(name).suffix.lower().lstrip(\".\")\n",
    "\n",
    "    if ext in (\"jpeg\", \"jpe\"):\n",
    "        ext = \"jpg\"\n",
    "    return base or \"file\", ext or \"bin\"\n",
    "\n",
    "\n",
    "def is_probably_image(content_type: str | None, ext: str) -> bool:\n",
    "    if content_type and content_type.lower().startswith(\"image/\"):\n",
    "        return True\n",
    "    return ext in {\"jpg\", \"jpeg\", \"png\", \"gif\", \"webp\", \"bmp\", \"tiff\"}\n",
    "\n",
    "\n",
    "def make_target_key(filename: str, ext: str) -> str:\n",
    "    # Keep the original filename, just add the prefix\n",
    "    return f\"{DST_PREFIX}/{filename}.{ext}\"\n",
    "\n",
    "\n",
    "def object_exists(bucket: str, key: str) -> bool:\n",
    "    try:\n",
    "        s3.head_object(Bucket=bucket, Key=key)\n",
    "        return True\n",
    "    except ClientError as e:\n",
    "        error_code = e.response.get(\"Error\", {}).get(\"Code\")\n",
    "        if error_code in (\"404\", \"NoSuchKey\", \"NotFound\"):\n",
    "            return False\n",
    "        elif error_code == \"400\":  # Bad Request\n",
    "            print(f\"[WARN] Invalid key format: {key}\")\n",
    "            return False\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "\n",
    "def read_image_from_s3(bucket: str, key: str) -> Image.Image:\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    data = obj[\"Body\"].read()\n",
    "    img = Image.open(io.BytesIO(data))\n",
    "    img.load()\n",
    "    return img\n",
    "\n",
    "\n",
    "def to_jpeg_bytes(img: Image.Image) -> bytes:\n",
    "    if img.mode in (\"RGBA\", \"LA\") or (img.mode == \"P\" and \"transparency\" in img.info):\n",
    "        bg = Image.new(\"RGB\", img.size, (255, 255, 255))\n",
    "        alpha_img = img.convert(\"RGBA\")\n",
    "        bg.paste(alpha_img, mask=alpha_img.split()[-1])\n",
    "        out = io.BytesIO()\n",
    "        bg.save(out, format=TARGET_PIL_FMT, **JPEG_SAVE_KW)\n",
    "        return out.getvalue()\n",
    "    else:\n",
    "        if img.mode not in (\"RGB\",):\n",
    "            img = img.convert(\"RGB\")\n",
    "        out = io.BytesIO()\n",
    "        img.save(out, format=TARGET_PIL_FMT, **JPEG_SAVE_KW)\n",
    "        return out.getvalue()\n",
    "\n",
    "\n",
    "def upload_bytes(bucket: str, key: str, content: bytes, content_type: str, metadata: dict | None = None):\n",
    "    extra = {\"ContentType\": content_type}\n",
    "    if metadata:\n",
    "        extra[\"Metadata\"] = metadata\n",
    "    s3.put_object(Bucket=bucket, Key=key, Body=content, **extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ca4622",
   "metadata": {},
   "source": [
    "This block defines utilities for identifying, converting, and uploading images during the formatting process.\n",
    "\n",
    "`utc_ts` generates a timestamp, while `split_name` extracts a clean base name and extension from an S3 key, normalizing formats like `.jpeg` to `.jpg`. The function `is_probably_image` checks if a file is an image based on MIME type or extension.\n",
    "\n",
    "`make_target_key` builds standardized output names using the pattern `image$dataset$filename.extension`, ensuring traceability and organization.\n",
    "\n",
    "The functions `object_exists`, `read_image_from_s3`, and `to_jpeg_bytes` handle object checking, reading, and image conversion respectively â€” converting images to JPEG with consistent quality and handling transparency safely.\n",
    "\n",
    "Finally, `upload_bytes` uploads the processed image bytes back to MinIO with appropriate content type and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9c3fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$19214085d36fb535c7dbf24d178dea1b__000095fc1d_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$19214085d36fb535c7dbf24d178dea1b__000095fc1d_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$1a426726a1e467b8e6360e980b03f611__00003a70b1_1.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$1a426726a1e467b8e6360e980b03f611__00003a70b1_1.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$1b1a47ccbb9d3b879c21952c03111b34__00003a70b1_2.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$1b1a47ccbb9d3b879c21952c03111b34__00003a70b1_2.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$4786052a58187b0a9c875fde7cf940c9__00010c7867_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$4786052a58187b0a9c875fde7cf940c9__00010c7867_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$6aaf18e8462526c1298ea0ccfaa861a5__0000b1e2b5_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$6aaf18e8462526c1298ea0ccfaa861a5__0000b1e2b5_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$6e0720efb93c1e5c1719b5b4c0c4cd7e__0000c79afb_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$6e0720efb93c1e5c1719b5b4c0c4cd7e__0000c79afb_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$89e502dee0f72c8b4b9382d5566e84c3__00010d44c7_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$89e502dee0f72c8b4b9382d5566e84c3__00010d44c7_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$9e7c94ba98c15fd4bf9c2014acc3a8d6__00007bfd16_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$9e7c94ba98c15fd4bf9c2014acc3a8d6__00007bfd16_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$a558f045aadaf96e44b67c18e77b0a87__00010c7867_1.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$a558f045aadaf96e44b67c18e77b0a87__00010c7867_1.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$b07c43b0325f168d7ce2b580d8e4b2a4__00003a70b1_0.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$b07c43b0325f168d7ce2b580d8e4b2a4__00003a70b1_0.jpg\n",
      "[OK] persistent_landing/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$f048b362a2cd8db702bf00f52307e6d5__00007bfd16_1.jpg -> s3://formatted-zone/images/image$adsdb-multimodal-food-data-management$2025-10-12T10-21-28Z$f048b362a2cd8db702bf00f52307e6d5__00007bfd16_1.jpg\n",
      "\n",
      "[UNIFY STATS] total_listed=11  converted=11  skipped=0\n"
     ]
    }
   ],
   "source": [
    "ts = utc_ts()\n",
    "paginator = s3.get_paginator(\"list_objects_v2\")\n",
    "pages = paginator.paginate(Bucket=SRC_BUCKET, Prefix=SRC_PREFIX)\n",
    "\n",
    "total = converted = skipped = 0\n",
    "\n",
    "for page in pages:\n",
    "    for obj in page.get(\"Contents\", []):\n",
    "        key = obj[\"Key\"]\n",
    "        if key.endswith(\"/\"):\n",
    "            continue\n",
    "\n",
    "        total += 1\n",
    "\n",
    "        try:\n",
    "            head = s3.head_object(Bucket=SRC_BUCKET, Key=key)\n",
    "        except ClientError as e:\n",
    "            print(f\"[WARN] head failed {key}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        base, ext = split_name(key)\n",
    "        ctype = head.get(\"ContentType\")\n",
    "\n",
    "        if not is_probably_image(ctype, ext):\n",
    "            print(f\"[SKIP] is not an image: {key} (ctype={ctype}, ext=.{ext})\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        dst_key = make_target_key(base, TARGET_EXT)\n",
    "\n",
    "        if not OVERWRITE and object_exists(DST_BUCKET, dst_key):\n",
    "            print(f\"[EXISTS] {dst_key}, jump (OVERWRITE=False)\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            img = read_image_from_s3(SRC_BUCKET, key)\n",
    "            jpg_bytes = to_jpeg_bytes(img)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] failed to convert {key}: {e}\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        metadata = {\n",
    "            \"src-bucket\": SRC_BUCKET,\n",
    "            \"src-key\": key,\n",
    "            \"dataset\": HF_DATASET,\n",
    "            \"unify-ts\": ts,\n",
    "            \"target-format\": TARGET_EXT,\n",
    "        }\n",
    "        try:\n",
    "            upload_bytes(DST_BUCKET, dst_key, jpg_bytes, TARGET_CTYPE, metadata)\n",
    "            converted += 1\n",
    "            print(f\"[OK] {key} -> s3://{DST_BUCKET}/{dst_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] upload failed {dst_key}: {e}\")\n",
    "            skipped += 1\n",
    "\n",
    "print(f\"\\n[UNIFY STATS] total_listed={total}  converted={converted}  skipped={skipped}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ab3f01",
   "metadata": {},
   "source": [
    "This block scans all images in the source bucket, converts them to a unified JPEG format, and uploads the results to the destination bucket.\n",
    "\n",
    "It iterates through all files under the image prefix, skipping directories and non-image files. Each valid image is read from MinIO, converted to JPEG using consistent settings, and uploaded under a standardized name (`image$dataset$filename.jpg`) with metadata describing its origin, dataset, and processing timestamp.\n",
    "\n",
    "The use of **JPEG (.jpg)** is intentional â€” it offers the best balance between **universal compatibility, file size, and processing speed**. Most visualization tools, web services, and ML pipelines natively support JPEG, making it a reliable and efficient standard for large-scale image handling.\n",
    "\n",
    "If a target file already exists and overwriting is disabled, it is skipped to avoid duplication. The script logs progress and counts totals for processed, converted, and skipped files, providing a clear summary of the unification process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
